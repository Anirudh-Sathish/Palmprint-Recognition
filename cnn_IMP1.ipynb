{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/miniconda3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# CNN implementation \n",
    "\n",
    "# import libs\n",
    "import os\n",
    "import numpy as np \n",
    "import torch \n",
    "import glob \n",
    "import torch.nn as nn \n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam \n",
    "from torch.autograd import Variable\n",
    "import torchvision \n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cuda available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5 , 0.5 , 0.5 ],[0.5 , 0.5 , 0.5 ]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory paths \n",
    "base_dir = \"basedata\"\n",
    "training = \"training\"\n",
    "validationString = \"validation\"\n",
    "\n",
    "# training ,validation locations \n",
    "training_path = os.path.join(base_dir,training)\n",
    "test_path = os.path.join(base_dir,\"testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader \n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(training_path , transform = transformer),\n",
    "    batch_size = 12 , shuffle= True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path , transform = transformer),\n",
    "    batch_size = 12 , shuffle= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class\n",
    "classes = os.listdir(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Neural Net \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes = 41):\n",
    "        super(ConvNet,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3 , out_channels=12 , kernel_size= 3, stride = 1 , padding = 1)\n",
    "         \n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size= 2)\n",
    "        # \n",
    "        self.conv2 = nn.Conv2d(in_channels = 12 , out_channels=20 , kernel_size= 3 , stride=1 , padding= 1)\n",
    "\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels= 20 , out_channels= 32 , kernel_size = 3 , stride = 1 , padding = 1)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(num_features = 32)\n",
    "\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(in_features= 32*150*150 , out_features= num_classes)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        # resizing \n",
    "        output  = output.view(-1,32*150*150)\n",
    "        # print(output.shape)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set HyperParameters \n",
    "num_epochs = 3 \n",
    "batch_size = 4 \n",
    "learning_rate = 0.001\n",
    "# Tune this later based on performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate testing_training , size \n",
    "train_count = len(glob.glob(training_path+'/**/*.JPG'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.JPG'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model \n",
    "model = ConvNet(num_classes=41).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , Loss : 0.0001938155182870105\n",
      "Epoch 1 , Loss : 0.00019751029321923852\n",
      "Epoch 2 , Loss : 0.19660410284996033\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i , (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # Forward pass \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # Backward pass \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # if (i+1) % 2 == 0:\n",
    "    print('Epoch {} , Loss : {}'.format(epoch,loss.item())) \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 64.28571428571429 % \n",
      "Accuracy of 023  : 100.0 %\n",
      "Accuracy of 004  : 100.0 %\n",
      "Accuracy of 033  : 66.66666666666667 %\n",
      "Accuracy of 037  : 100.0 %\n",
      "Accuracy of 010  : 0.0 %\n",
      "Accuracy of 013  : 100.0 %\n",
      "Accuracy of 035  : 66.66666666666667 %\n",
      "Accuracy of 039  : 66.66666666666667 %\n",
      "Accuracy of 001  : 0.0 %\n",
      "Accuracy of 025  : 100.0 %\n",
      "Accuracy of 041  : 100.0 %\n",
      "Accuracy of 029  : 100.0 %\n",
      "Accuracy of 016  : 20.0 %\n",
      "Accuracy of 009  : 100.0 %\n",
      "Accuracy of 026  : 33.333333333333336 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 022  : 100.0 %\n",
      "Accuracy of 006  : 40.0 %\n",
      "Accuracy of 027  : 100.0 %\n",
      "Accuracy of 030  : 100.0 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 034  : 100.0 %\n",
      "Accuracy of 021  : 100.0 %\n",
      "Accuracy of 024  : 50.0 %\n",
      "Accuracy of 005  : 33.333333333333336 %\n",
      "Accuracy of 031  : 100.0 %\n",
      "Accuracy of 007  : 0.0 %\n",
      "Accuracy of 008  : 50.0 %\n",
      "Accuracy of 017  : 50.0 %\n",
      "Accuracy of 014  : 66.66666666666667 %\n",
      "Accuracy of 020  : 66.66666666666667 %\n",
      "Accuracy of 036  : 40.0 %\n",
      "Accuracy of 038  : 100.0 %\n",
      "Accuracy of 015  : 33.333333333333336 %\n",
      "Accuracy of 011  : 100.0 %\n",
      "Accuracy of 019  : 33.333333333333336 %\n",
      "Accuracy of 032  : 33.333333333333336 %\n",
      "Accuracy of 018  : 100.0 %\n",
      "Accuracy of 040  : 100.0 %\n",
      "Accuracy of 012  : 33.333333333333336 %\n",
      "Accuracy of 003  : 50.0 %\n"
     ]
    }
   ],
   "source": [
    "# For testing \n",
    "with torch.no_grad():\n",
    "    n_correct = 0 \n",
    "    n_samples = 0 \n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "\n",
    "    for images,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _ , predicted = torch.max(outputs , 1)\n",
    "        n_samples +=labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] +=1\n",
    "            n_class_samples[label]+=1\n",
    "    \n",
    "    accuracy = 100.0* n_correct/n_samples \n",
    "    print('Accuracy  : {} % '.format(accuracy))\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        if n_class_samples[i] == 0:\n",
    "            print('Didnt get the sample in test ')\n",
    "        else:\n",
    "            acc = 100*n_class_correct[i]/n_class_samples[i]\n",
    "            print('Accuracy of {}  : {} %'.format(classes[i],acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6abc19a8e1fc5a4ded62ce588c026b0071d26d608f7dba32576a5a9967215991"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
