{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 127] The specified procedure could not be found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# CNN implementation \n",
    "\n",
    "# import libs\n",
    "import os\n",
    "import numpy as np \n",
    "import torch \n",
    "import glob \n",
    "import torch.nn as nn \n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam \n",
    "from torch.autograd import Variable\n",
    "import torchvision \n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if cuda available \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5 , 0.5 , 0.5 ],[0.5 , 0.5 , 0.5 ]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory paths \n",
    "base_dir = \"basedata_ROI/session1\"\n",
    "training = \"train\"\n",
    "validationString = \"val\"\n",
    "\n",
    "# training ,validation locations \n",
    "training_path = os.path.join(base_dir,training)\n",
    "test_path = os.path.join(base_dir,\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader \n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(training_path , transform = transformer),\n",
    "    batch_size = 12 , shuffle= True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path , transform = transformer),\n",
    "    batch_size = 12 , shuffle= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class\n",
    "classes = os.listdir(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Neural Net \n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes = 41):\n",
    "        super(ConvNet,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels= 3 , out_channels=12 , kernel_size= 3, stride = 1 , padding = 1)\n",
    "         \n",
    "        self.bn1 = nn.BatchNorm2d(num_features = 12)\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size= 2)\n",
    "        # \n",
    "        self.conv2 = nn.Conv2d(in_channels = 12 , out_channels=20 , kernel_size= 3 , stride=1 , padding= 1)\n",
    "\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels= 20 , out_channels= 32 , kernel_size = 3 , stride = 1 , padding = 1)\n",
    "\n",
    "        self.bn3 = nn.BatchNorm2d(num_features = 32)\n",
    "\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.fc = nn.Linear(in_features= 32*150*150 , out_features= num_classes)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        # resizing \n",
    "        output  = output.view(-1,32*150*150)\n",
    "        # print(output.shape)\n",
    "        output = self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set HyperParameters \n",
    "num_epochs = 3 \n",
    "batch_size = 4 \n",
    "learning_rate = 0.001\n",
    "# Tune this later based on performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate testing_training , size \n",
    "train_count = len(glob.glob(training_path+'/**/*.JPG'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.JPG'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model \n",
    "model = ConvNet(num_classes=41).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters() , lr = learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[39m# Backward pass \u001b[39;00m\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 13\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     14\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     17\u001b[0m \u001b[39m# if (i+1) % 2 == 0:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i , (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # Forward pass \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # Backward pass \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # if (i+1) % 2 == 0:\n",
    "    print('Epoch {} , Loss : {}'.format(epoch,loss.item())) \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 64.28571428571429 % \n",
      "Accuracy of 023  : 100.0 %\n",
      "Accuracy of 004  : 100.0 %\n",
      "Accuracy of 033  : 66.66666666666667 %\n",
      "Accuracy of 037  : 100.0 %\n",
      "Accuracy of 010  : 0.0 %\n",
      "Accuracy of 013  : 100.0 %\n",
      "Accuracy of 035  : 66.66666666666667 %\n",
      "Accuracy of 039  : 66.66666666666667 %\n",
      "Accuracy of 001  : 0.0 %\n",
      "Accuracy of 025  : 100.0 %\n",
      "Accuracy of 041  : 100.0 %\n",
      "Accuracy of 029  : 100.0 %\n",
      "Accuracy of 016  : 20.0 %\n",
      "Accuracy of 009  : 100.0 %\n",
      "Accuracy of 026  : 33.333333333333336 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 022  : 100.0 %\n",
      "Accuracy of 006  : 40.0 %\n",
      "Accuracy of 027  : 100.0 %\n",
      "Accuracy of 030  : 100.0 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 034  : 100.0 %\n",
      "Accuracy of 021  : 100.0 %\n",
      "Accuracy of 024  : 50.0 %\n",
      "Accuracy of 005  : 33.333333333333336 %\n",
      "Accuracy of 031  : 100.0 %\n",
      "Accuracy of 007  : 0.0 %\n",
      "Accuracy of 008  : 50.0 %\n",
      "Accuracy of 017  : 50.0 %\n",
      "Accuracy of 014  : 66.66666666666667 %\n",
      "Accuracy of 020  : 66.66666666666667 %\n",
      "Accuracy of 036  : 40.0 %\n",
      "Accuracy of 038  : 100.0 %\n",
      "Accuracy of 015  : 33.333333333333336 %\n",
      "Accuracy of 011  : 100.0 %\n",
      "Accuracy of 019  : 33.333333333333336 %\n",
      "Accuracy of 032  : 33.333333333333336 %\n",
      "Accuracy of 018  : 100.0 %\n",
      "Accuracy of 040  : 100.0 %\n",
      "Accuracy of 012  : 33.333333333333336 %\n",
      "Accuracy of 003  : 50.0 %\n"
     ]
    }
   ],
   "source": [
    "# For testing \n",
    "with torch.no_grad():\n",
    "    n_correct = 0 \n",
    "    n_samples = 0 \n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "\n",
    "    for images,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _ , predicted = torch.max(outputs , 1)\n",
    "        n_samples +=labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] +=1\n",
    "            n_class_samples[label]+=1\n",
    "    \n",
    "    accuracy = 100.0* n_correct/n_samples \n",
    "    print('Accuracy  : {} % '.format(accuracy))\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        if n_class_samples[i] == 0:\n",
    "            print('Didnt get the sample in test ')\n",
    "        else:\n",
    "            acc = 100*n_class_correct[i]/n_class_samples[i]\n",
    "            print('Accuracy of {}  : {} %'.format(classes[i],acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6abc19a8e1fc5a4ded62ce588c026b0071d26d608f7dba32576a5a9967215991"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
