{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np \n",
    "import torchvision \n",
    "from torchvision import datasets,transforms,models \n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt \n",
    "import time \n",
    "import os \n",
    "import copy \n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transformer = transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5 , 0.5 , 0.5 ],[0.5 , 0.5 , 0.5 ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory paths \n",
    "base_dir = \"basedata\"\n",
    "training = \"training\"\n",
    "validationString = \"validation\"\n",
    "\n",
    "# training ,validation locations \n",
    "training_path = os.path.join(base_dir,training)\n",
    "test_path = os.path.join(base_dir,\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader \n",
    "train_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(training_path , transform = transformer),\n",
    "    batch_size = 12 , shuffle= True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path , transform = transformer),\n",
    "    batch_size = 12 , shuffle= True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/miniconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/anirudh/miniconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/anirudh/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [07:36<00:00, 103kB/s]   \n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get class\n",
    "classes = os.listdir(training_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set HyperParameters \n",
    "num_epochs = 3 \n",
    "batch_size = 4 \n",
    "learning_rate = 0.001\n",
    "# Tune this later based on performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate testing_training , size \n",
    "train_count = len(glob.glob(training_path+'/**/*.JPG'))\n",
    "test_count = len(glob.glob(test_path+'/**/*.JPG'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs,len(classes))\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , Loss : 3.6536941528320312\n",
      "Epoch 1 , Loss : 3.658282518386841\n",
      "Epoch 2 , Loss : 3.684581756591797\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i , (images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "\n",
    "        # Forward pass \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # Backward pass \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # if (i+1) % 2 == 0:\n",
    "    print('Epoch {} , Loss : {}'.format(epoch,loss.item())) \n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy  : 76.3975155279503 % \n",
      "Accuracy of 023  : 100.0 %\n",
      "Accuracy of 004  : 100.0 %\n",
      "Accuracy of 033  : 100.0 %\n",
      "Accuracy of 037  : 100.0 %\n",
      "Accuracy of 010  : 33.333333333333336 %\n",
      "Accuracy of 013  : 100.0 %\n",
      "Accuracy of 035  : 100.0 %\n",
      "Accuracy of 039  : 66.66666666666667 %\n",
      "Accuracy of 001  : 50.0 %\n",
      "Accuracy of 025  : 100.0 %\n",
      "Accuracy of 041  : 100.0 %\n",
      "Accuracy of 029  : 33.333333333333336 %\n",
      "Accuracy of 016  : 100.0 %\n",
      "Accuracy of 009  : 75.0 %\n",
      "Accuracy of 026  : 33.333333333333336 %\n",
      "Accuracy of 028  : 100.0 %\n",
      "Accuracy of 022  : 100.0 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 027  : 100.0 %\n",
      "Accuracy of 030  : 33.333333333333336 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 034  : 100.0 %\n",
      "Accuracy of 021  : 100.0 %\n",
      "Accuracy of 024  : 50.0 %\n",
      "Accuracy of 005  : 100.0 %\n",
      "Accuracy of 031  : 100.0 %\n",
      "Accuracy of 007  : 100.0 %\n",
      "Didnt get the sample in test \n",
      "Accuracy of 017  : 50.0 %\n",
      "Accuracy of 014  : 75.0 %\n",
      "Accuracy of 020  : 80.0 %\n",
      "Accuracy of 036  : 100.0 %\n",
      "Accuracy of 038  : 100.0 %\n",
      "Accuracy of 015  : 33.333333333333336 %\n",
      "Accuracy of 011  : 100.0 %\n",
      "Accuracy of 019  : 0.0 %\n",
      "Accuracy of 032  : 100.0 %\n",
      "Accuracy of 018  : 100.0 %\n",
      "Accuracy of 040  : 75.0 %\n",
      "Accuracy of 012  : 100.0 %\n",
      "Accuracy of 003  : 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# For testing \n",
    "with torch.no_grad():\n",
    "    n_correct = 0 \n",
    "    n_samples = 0 \n",
    "    n_class_correct = [0 for i in range(len(classes))]\n",
    "    n_class_samples = [0 for i in range(len(classes))]\n",
    "\n",
    "    for images,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        _ , predicted = torch.max(outputs , 1)\n",
    "        n_samples +=labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] +=1\n",
    "            n_class_samples[label]+=1\n",
    "    \n",
    "    accuracy = 100.0* n_correct/n_samples \n",
    "    print('Accuracy  : {} % '.format(accuracy))\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        if n_class_samples[i] == 0:\n",
    "            print('Didnt get the sample in test ')\n",
    "        else:\n",
    "            acc = 100*n_class_correct[i]/n_class_samples[i]\n",
    "            print('Accuracy of {}  : {} %'.format(classes[i],acc))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6abc19a8e1fc5a4ded62ce588c026b0071d26d608f7dba32576a5a9967215991"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
